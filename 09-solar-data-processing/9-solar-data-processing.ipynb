{
 "metadata": {
  "name": "",
  "signature": "sha256:90b4585a9cd5c153dd48dd7636e24faebd14d9e7ea333df2b0e025573a200352"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Processing Solar Data with SunPy"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Objectives"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Learn how to perform common processing tasks on a Map object\n",
      " - Rebin\n",
      " - Crop\n",
      " - Rotate\n",
      " - Account for solar differential rotation\n",
      "- Learn how to perform common processing tasks on a LightCurve\n",
      "- Learn how to perform common processing tasks on a Spectrum"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Working with Maps"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cropping and rebinning Maps"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So far we have worked mostly with entire Maps, and have simply adjusted the plot limits when we want to look at a particular portion of them. This is inefficient though, since the full data array for the Map is still stored in memory, we're just not looking at it. If we know we won't need this excess data again, we can instead get rid of it entirely by cropping the Map with the `submap()` method.\n",
      "\n",
      "The required input for `submap()` is two lists - one for the x direction and one for the y - which each contain the minimum and maximum extents of the data you want. By default these values are taken to be in data coordinates (usually arcsec), but you can use pixel values instead by setting the `units` keyword to `'pixels'` when calling `submap()`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Usual setup and import statements\n",
      "%matplotlib inline\n",
      "import sunpy\n",
      "import sunpy.map\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Create a new AIAMap\n",
      "aiamap = sunpy.map.Map(\"rotate_demo1.fits\")\n",
      "# Crop to look at something on the limb\n",
      "#cropped = aiamap.submap([450, 750], [-1000, -700])\n",
      "cropped = aiamap.submap([2820, 3332], [300, 812], units='pixels')\n",
      "# Have a quick look\n",
      "cropped.peek(vmax=400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `submap()` function also handles all the necessary changes in the header data so the Map knows that it has been cropped."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Rotating Maps"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is not uncommon to need to rotate an image. You may want to look at a feature in a particular way, or you may need to account for the rotation of the instrument. Either way, this can be achieved with the `Map.rotate()` method, which does exactly what you would expect it to do. It can be passed a number of degrees or a rotation matrix (or neither - we'll get to that in a minute) and it will return a new Map which is a copy of the old one but rotated by the appropriate amount (anti-clockwise if degrees are specified). Again, all the relevant header data is updated when you `rotate()` a Map.\n",
      "\n",
      "Take the image above for example. This plot is fine, but would look a bit neater if the feature were the right way up. So we can rotate the Map like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Rotate the feature upright and replot it\n",
      "rotated = cropped.rotate(145)\n",
      "rotated.peek(vmax=400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that rotating an already cropped Map has caused patches of missing data within our new plot. Really we should have rotated the data first and then cropped it, to avoid this problem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Rotate the original Map first\n",
      "rotated = aiamap.rotate(145)\n",
      "# Then crop it - note that the data coordinates have changed!\n",
      "cropped = rotated.submap([-150, 150], [900, 1200])\n",
      "# Have a quick look\n",
      "cropped.peek(vmax=400)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Every Map instance has a rotation matrix in the metdata which defines the current rotation of the image, and which is updated whenever `rotate()` is called. If `rotate()` is called without any input, it will revert to its default behaviour, which is to account for that rotation. This means that we can easily reverse the rotation we applied to our image in the previous example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unrotated = rotated.rotate()\n",
      "unrotated.peek()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The initial value of the metadata's rotation matrix describes the instrument rotation. This means that we can also use `rotate()` to offset that. The example needs to be a little more extreme to demonstrate this..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a new AIAMap\n",
      "aiamap = sunpy.map.Map(\"rotate_demo2.fits\")\n",
      "# Account for instrument rotation\n",
      "aiamap = aiamap.rotate()\n",
      "aiamap.peek()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Differential rotation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Challenges"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Do some things"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Working with LightCurves"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analysing lightcurve data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see how well the LYRA lightcurves correlate with each other. For this, we need to use functions in numpy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import sunpy.lightcurve\n",
      "\n",
      "lyra_lc = sunpy.lightcurve.LYRALightCurve.create('2011-06-07').truncate('2011-06-07 06:00','2011-06-07 08:00')\n",
      "cross_correlation = np.correlate(lyra_lc.data['CHANNEL3'],lyra_lc.data['CHANNEL4'])\n",
      "print cross_correlation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can find the point in time of maximum emission for each channel, and compare it with the maximum in the GOES long (1-8A) and short (0.5-4A) channel emission."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timeofmax_al = lyra_lc.data['CHANNEL3'].idxmax()\n",
      "timeofmax_zr = lyra_lc.data['CHANNEL4'].idxmax()\n",
      "print 'LYRA Al: ', timeofmax_al\n",
      "print 'LYRA Zr: ', timeofmax_zr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that the GOES short channel peaks first at 06:39:00, followed by the GOES long channel at 06:41:24, while the LYRA emission peaks later at around 06:44:45. We could add this information to our plot like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(10,5))\n",
      "plt.plot(lyra_lc.data.index,lyra_lc.data['CHANNEL3'],color='blue',label='Al filter')\n",
      "plt.plot(lyra_lc.data.index,lyra_lc.data['CHANNEL4'],color='red',label='Zr filter')\n",
      "plt.ylim([0.0005,0.0055])\n",
      "plt.ylabel('Flux (Wm$^{-2}$)')\n",
      "\n",
      "plt.axvline(timeofmax_al,color='blue',linestyle='dashed',linewidth=2)\n",
      "plt.axvline(timeofmax_zr,color='red',linestyle='dashed')\n",
      "\n",
      "plt.legend()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Working with Spectrums"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SunPy currently supports reading dynamic spectra from e-Callisto instruments. The main class that is used for this is CallistoSpectrogram. SunPy also comes with an example image that shows a radio burst observed at Rosse Observatory (aka. BIR; Birr Castle, Co. Offaly, Ireland) that can be found in sunpy.CALLISTO_IMAGE:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sunpy.spectra.sources.callisto import CallistoSpectrogram\n",
      "image = CallistoSpectrogram.read(sunpy.CALLISTO_IMAGE)\n",
      "image.peek()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now notice that there seems to be something interesting that has been cut off at the corner of the image, so we use the extend method to request more data from the server. It optionally takes the amount of minutes we want to request from the server (negative values mean we want to add data that was registered before our existing local data), if none are given it defaults to 15 minutes (the size of one e-Callisto file).:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "more = image.extend()\n",
      "more.peek()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will, for the purposes of this demonstration, continue working with the original image, though.\n",
      "\n",
      "You can then perform automatic constant background subtraction by using the subtract_bg() method. The resulting image will be clipped at 0 using the min parameter of peek in order to avoid negative values.:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nobg = image.subtract_bg()\n",
      "nobg.peek(vmin=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want to see the background determined by the automatic subtraction, you can use the auto_const_bg() method and visualize the resulting data using pyplot.plot().:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure()\n",
      "bg = image.auto_const_bg()\n",
      "plt.plot(image.freq_axis, bg)\n",
      "plt.xlabel(\"Frequency [MHz]\")\n",
      "plt.ylabel(\"Intensity\")\n",
      "plt.show() # This might not be necessary if you are using pylab."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let us say we want to isolate the interesting bit (which starts around 10:38) from the boring background; there is a method called in_interval() that allows us to take the part of an image that is within a specified interval. Leaving out the second argument it defaults to the end time of the file.:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting = nobg.in_interval(\"10:38\")\n",
      "interesting.peek(vmin=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get rid of the noise, we could also clip low intensities.:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "interesting.peek(vmin=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we want more context, we can also join together different images into a large one in time (note that this does more than just concatenating the array and the axes \u2013 it also considers possible overlap or gaps).:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c1 = CallistoSpectrogram.read(\"BIR_20110922_101500_01.fit\")\n",
      "c2 = CallistoSpectrogram.read(\"BIR_20110922_103000_01.fit\")\n",
      "d = CallistoSpectrogram.join_many([c1, c2])\n",
      "d.peek()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could also get the from_range method to get data between those two points directly from the archive and joined together (though that will fetch all frequencies of BIR).:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = CallistoSpectrogram.from_range(\"BIR\", \"2011-09-22T10:15:00\", \"2011-09-22T10:45:00\")\n",
      "d.peek()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The peek() method returns a special kind of figure that offers convenience features needed for analyzing spectrograms, a SpectroFigure. By using its time_freq(), we can select points on the figure and frequency-time information of them will be returned as a TimeFreq. Time is stored as offsets in seconds from TimeFreq.start. Note that if you use plot() instead of plot(), you have to create a SpectroFigure by using SpectroFigure:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = image.peek()\n",
      "time_freq = fig.time_freq()\n",
      "# Select points.\n",
      "time_freq.time\n",
      "#array([   0.  ,   54.5 ,  104.  ,  163.25])\n",
      "time_freq.freq\n",
      "#array([ 68.76923077,  59.29888786,  48.50092678,  36.46385542])\n",
      "\n",
      "time_freq.peek(marker='o', linestyle='--')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}